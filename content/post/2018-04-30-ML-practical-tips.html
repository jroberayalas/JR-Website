---
title: Machine Learning Practical Tips
author: José Roberto Ayala Solares
date: '2018-04-30'
slug: ML-practical-tips
categories: []
tags:
  - notes
  - machine learning
summary: Practical tips from......
draft: true
---



<p><a href="{{% ref "#probando" %}}">yomero</a> {#probando}</p>
<div id="feature-preprocessing" class="section level2">
<h2>Feature Preprocessing</h2>
<div id="numeric-features" class="section level3">
<h3>Numeric features</h3>
<p>Scaling: MinMax or Standardization (to make features’ impacts on non-tree-based models roughly similar. Tree-based models do not depend on scaling).</p>
<p>Clipping (winsorization): for outliers</p>
<p>Rank transformation: set spaces between proper assorted values to be equal. It can be a better option than MinMax if we have outliers because rank transformation will move the outliers closer to other objects.</p>
<p>Log and Fractional power (i.e. sqrt) transformations: especially useful for neural networks. These can be useful because they drive 2 big values closer to the feature’s average value. Also, values around zero become more distinguishable.</p>
<p>Sometimes it is useful to train a model on concatenated data frames produced by different preprocessings, or to mix models different preprocessed data</p>
</div>
<div id="categorical-and-ordinal-features" class="section level3">
<h3>Categorical and ordinal features</h3>
<p>Label encoding: map each unique value to different numbers. Non-tree-based models require extra step by creating one-hot encoding.</p>
<p>Frequency encoding: maps categories to their frequencies. This preserves information about values’ distribution and can help both linear and tree models. If two features have the same frequency, they become indistinguishable.</p>
<p>One-hot encoding: mainly used for non-tree-based models. It can introduce a lot of sparsity. To save memory, usage of sparse matrices can be benefitial if number of non-zero values is far less than half of total values.</p>
</div>
</div>
<div id="feature-generation" class="section level2">
<h2>Feature Generation</h2>
<p>It is powered by prior knowledge and EDA.</p>
<p>Feature interaction between different categorical features.</p>
</div>
<div id="datetime" class="section level2">
<h2>Datetime</h2>
<ol style="list-style-type: decimal">
<li>Periodicity: second, minute, hour, day number in week, month, season, year</li>
<li>Time since either row-independent (a common date) or row-dependent (number of days left until next holiday / number of days passed since last holiday) event</li>
<li>Difference between dates</li>
</ol>
</div>
<div id="coordinates" class="section level2">
<h2>Coordinates</h2>
<ol style="list-style-type: decimal">
<li>Extract interesting places from the train/test data or additional data</li>
<li>Calculate distances to centers of clusters</li>
<li>Add aggregated statistics for surrounding data</li>
</ol>
</div>
<div id="missing-data" class="section level1">
<h1>Missing data</h1>
<div id="missing-value-imputation" class="section level2">
<h2>Missing value imputation</h2>
<ol style="list-style-type: decimal">
<li>Replace NA with a value outside fixed value range (performance of linear models and NNs can suffer)</li>
<li>Add a binary feature that indicates missingness</li>
<li>Replace with mean or median (beneficial for linear models and NN, but not for tree-based models)</li>
<li>Reconstruct the value</li>
</ol>
<p>Be careful with imputed variables if you want to generate new features from them. Avoid replacing mising values before feature generation.</p>
<p>Outliers can be treated as missing values.</p>
<p>XGBoost and CatBoost can handle NA.</p>
</div>
</div>
<div id="feature-extraction-from-text-and-images" class="section level1">
<h1>Feature extraction from text and images</h1>
<div id="for-text" class="section level2">
<h2>For text</h2>
<ol style="list-style-type: decimal">
<li>Bag of words</li>
<li>Word embeddings (word2vec)</li>
</ol>
<p>Pipeline for bag of words (BOW): * Preprocessing: 1. Lowercase 2. Lemmatization 3. Stemming 4. Stopwords</p>
<ul>
<li><p>BOW (Ngrams can help to use local context)</p></li>
<li>Postprocessing:</li>
</ul>
<ol style="list-style-type: decimal">
<li>Term frequency and Inverse document frequency (TFiDF) transformations</li>
</ol>
</div>
<div id="for-images" class="section level2">
<h2>For images</h2>
<ul>
<li>Use pretrained models</li>
<li>Data augmentation</li>
</ul>
<p>It is crucial to understand the data generation process to set up a proper validation scheme.</p>
<p>Make distance plots (correlations, time that a feature is bigger than another feature).</p>
<p>Check that the data is shuffle: use mean and rolling mean of a feature or outcome variable.</p>
<pre class="r"><code>library(reticulate)</code></pre>
<pre><code>## Warning: package &#39;reticulate&#39; was built under R version 3.4.4</code></pre>
<pre class="python"><code>## sys.executable contains full path of the currently running Python interpreter. 
# import sys
# print(sys.executable)
import pandas as pd
titanic = pd.read_excel(&#39;http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic3.xls&#39;)
print titanic.head()</code></pre>
<pre><code>##    pclass  survived                                             name     sex  \
## 0       1         1                    Allen, Miss. Elisabeth Walton  female   
## 1       1         1                   Allison, Master. Hudson Trevor    male   
## 2       1         0                     Allison, Miss. Helen Loraine  female   
## 3       1         0             Allison, Mr. Hudson Joshua Creighton    male   
## 4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   
## 
##        age  sibsp  parch  ticket      fare    cabin embarked boat   body  \
## 0  29.0000      0      0   24160  211.3375       B5        S    2    NaN   
## 1   0.9167      1      2  113781  151.5500  C22 C26        S   11    NaN   
## 2   2.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   
## 3  30.0000      1      2  113781  151.5500  C22 C26        S  NaN  135.0   
## 4  25.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   
## 
##                          home.dest  
## 0                     St Louis, MO  
## 1  Montreal, PQ / Chesterville, ON  
## 2  Montreal, PQ / Chesterville, ON  
## 3  Montreal, PQ / Chesterville, ON  
## 4  Montreal, PQ / Chesterville, ON</code></pre>
<pre class="r"><code>#library(ggplot2)
#ggplot(py$titanic, aes(x = age)) +
#    geom_hist()</code></pre>
</div>
</div>
